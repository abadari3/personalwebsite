<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Automatic Speed Detection from Dashcam Video</title>

    <link rel="stylesheet" href="{{ url_for('static', filename='css/styles.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/github-light.css') }}">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Automatic Speed Detection from Dashcam Video</h1>
        <h3>CS 4476: Computer Vision</h3>
        <h4>Georgia Tech</h4>
        
        <p>Ananda Badari<br>
        Evan Juncal<br>
        Kevin Park<br>
        Rohit Ramakrishnan</p>
        
        <img src="https://www.roboticsbusinessreview.com/wp-content/uploads/2019/08/AdobeStock_222100885.jpeg">

        <img src="https://i.pinimg.com/originals/ed/d3/3f/edd33f73975cbf964c863990f514247d.jpg">
        
        <img src="https://geospatialmedia.s3.amazonaws.com/wp-content/uploads/2017/08/LiDAR_detection-matrix_%C2%A9LeddarTech.jpg">

        <p class="view"><a href="https://github.gatech.edu/abadari3/Automatic-Speed-Detection-from-Dashcam-Video">View the Project on GitHub <small>Automatic Speed Detection from Dashcam Video</small></a></p>


      </header>
      <section>
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction/Background</h3>

<p>
  We are a group of undergraduate students at Georgia Tech, who are using Computer Vision techniques to determine the speed of a car. Since one of the most visible and cutting edge applications of Computer Vision is in autonomous vehicles, we were interested in pursuing a topic dealing with self-driving cars, and are attempting to solve the <a target="_blank" href="https://github.com/commaai/speedchallenge">comma.ai programming challenge</a> as our project for CS 4476: Computer Vision.
</p>

<h3>
  <a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true">
    <span aria-hidden="true" class="octicon octicon-link"></span>
  </a>
  Problem Statement
</h3>

<p>
  The goal is to predict the speed of a car given its dashcam video. That is, given a dashcam video of a car, we want to assign each frame with the approximate instantaneous speed during that frame. Thus, we can model the entire car's journey from start to finish by referencing the speeds on the individual frames. <br><br>

  Expected Input: A 20fps video from the dashcam of a car<br>
  Expected Output: An estimated speed of the car for each video frame<br><br>

  There will be a training data which consists of a dashcam video and a text file indicating the true speed of the car per frame. Then, there will be a test video from the same dashcam in the same mounting position which we will use to estimate the speed of the car.



</p>

<h3>
  <a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true">
    <span aria-hidden="true" class="octicon octicon-link"></span>
  </a>
  Techincal Approach
</h3>

<p>
We have several potential approaches to this problem and may try a bunch of them to ensure we get the speed of the car more accurately per frame.<br>

<ol>
  <li>We will use SIFT (Scale Invariant Feature Transform) to find all of the useful features inside each frame of the video and map them to the same features of the previous frame. This will give us the necessary data to create an optical flow map of the image. Then, we should be able to deduce the speed from the change in magnitude of the optical flow. If the magnitude is mostly zero then, the car is probably stationary, and vice-versa. For this final step, we will utilize supervised machine learning to predict a scalar speed from an optical flow map.</li>
  <figure>
    <img src="https://raw.githubusercontent.com/abadari3/anandabadari.com/master/images/exopticalflowmap.png" style="width:100%">
    <figcaption>Example Optical Flow Map</figcaption>
  </figure>
  <li>We can also use SURF (Speeded up Robust features) which is several times faster (up for debate) than SIFT. It roughly follows the same steps as SIFT, except the implementation is kind of different. A more in depth description of the algorithm can be covered in <a target="_blank" href="https://people.ee.ethz.ch/~surf/eccv06.pdf">this paper.</a> The issue is it’s patented so there may be trouble using the algorithm.</li> <br>
  <li>Another option is to feed optical flows into CNN (convolution neural network) model. First, frames would be fed into the Optical Flow algorithm. Then apply a Canny edge detector. Then append back to the original image to highlight the road/lanes properly. After that, we can do NVIDIA CNN on the manipulated frames. </li><br>
  <li>Also, we could do try the above idea using R-CNN (Region Based Convolutional Neural Networks) or LSTM (Long short-term memory) instead of a CNN.</li>
</ol> 

</p>

<h3>
  <a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true">
    <span aria-hidden="true" class="octicon octicon-link"></span>
  </a>Experimental Methods
</h3>

<p>
We will use datasets provided here by the <a target="_blank" href="https://github.com/commaai/speedchallenge">comma.ai programming challenge</a> for test data, training data, and labels for a sample dash-cam video. <br><br>
For the SIFT algorithm, we will most likely use <a target="_blank" href="https://robwhess.github.io/opensift/">OpenSift.</a> <br><br>
We will have to develop our own algorithm for deducing the features from SIFT into an optical flow map while removing unwanted features. For example, a car in front of us can be detected as a feature in SIFT; however, we do not want to use it as it will appear mostly stationary in the optical flow graph as long as the driver is maintaining a constant distance while driving. Therefore, we will need a way to remove moving objects from the feature set and stick to the non-moving features such as road markings and surrounding buildings.
</p>

<h3>
  <a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true">
    <span aria-hidden="true" class="octicon octicon-link"></span>
  </a>
  Potential Results
</h3>

<p>
  The datasets provided by comma.ai consist of training video containing 20400 frames and is shot at 20fps. The training video is from the perspective of a camera mounted on the car’s dashboard. There is also a text file provided containing the speed of the car at each frame in the training video. We will then run our algorithm on the provided test dataset, a video with 10798 frames shot at 20fps, and try to estimate the speed of the car at each frame. We will evaluate our speed estimates for each frame using mean squared error to determine our accuracy. The goal is to have a mean squared error of less than 10. This was the benchmark given by comma.ai as good results. 

</p>

      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
